{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>F</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>M</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>M</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>F</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>M</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex  Length  Diameter  Height  Whole weight  Shucked weight  \\\n",
       "0      M   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1      M   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2      F   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3      M   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4      I   0.330     0.255   0.080        0.2050          0.0895   \n",
       "...   ..     ...       ...     ...           ...             ...   \n",
       "4172   F   0.565     0.450   0.165        0.8870          0.3700   \n",
       "4173   M   0.590     0.440   0.135        0.9660          0.4390   \n",
       "4174   M   0.600     0.475   0.205        1.1760          0.5255   \n",
       "4175   F   0.625     0.485   0.150        1.0945          0.5310   \n",
       "4176   M   0.710     0.555   0.195        1.9485          0.9455   \n",
       "\n",
       "      Viscera weight  Shell weight  Rings  \n",
       "0             0.1010        0.1500     15  \n",
       "1             0.0485        0.0700      7  \n",
       "2             0.1415        0.2100      9  \n",
       "3             0.1140        0.1550     10  \n",
       "4             0.0395        0.0550      7  \n",
       "...              ...           ...    ...  \n",
       "4172          0.2390        0.2490     11  \n",
       "4173          0.2145        0.2605     10  \n",
       "4174          0.2875        0.3080      9  \n",
       "4175          0.2610        0.2960     10  \n",
       "4176          0.3765        0.4950     12  \n",
       "\n",
       "[4177 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv(\"abalone.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex               0\n",
       "Length            0\n",
       "Diameter          0\n",
       "Height            0\n",
       "Whole weight      0\n",
       "Shucked weight    0\n",
       "Viscera weight    0\n",
       "Shell weight      0\n",
       "Rings             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check whether there are null values or not\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex                object\n",
       "Length            float64\n",
       "Diameter          float64\n",
       "Height            float64\n",
       "Whole weight      float64\n",
       "Shucked weight    float64\n",
       "Viscera weight    float64\n",
       "Shell weight      float64\n",
       "Rings               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check the DataType of each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Length</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986812</td>\n",
       "      <td>0.827554</td>\n",
       "      <td>0.925261</td>\n",
       "      <td>0.897914</td>\n",
       "      <td>0.903018</td>\n",
       "      <td>0.897706</td>\n",
       "      <td>0.556720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diameter</th>\n",
       "      <td>0.986812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833684</td>\n",
       "      <td>0.925452</td>\n",
       "      <td>0.893162</td>\n",
       "      <td>0.899724</td>\n",
       "      <td>0.905330</td>\n",
       "      <td>0.574660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>0.827554</td>\n",
       "      <td>0.833684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.819221</td>\n",
       "      <td>0.774972</td>\n",
       "      <td>0.798319</td>\n",
       "      <td>0.817338</td>\n",
       "      <td>0.557467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whole weight</th>\n",
       "      <td>0.925261</td>\n",
       "      <td>0.925452</td>\n",
       "      <td>0.819221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969405</td>\n",
       "      <td>0.966375</td>\n",
       "      <td>0.955355</td>\n",
       "      <td>0.540390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shucked weight</th>\n",
       "      <td>0.897914</td>\n",
       "      <td>0.893162</td>\n",
       "      <td>0.774972</td>\n",
       "      <td>0.969405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931961</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>0.420884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Viscera weight</th>\n",
       "      <td>0.903018</td>\n",
       "      <td>0.899724</td>\n",
       "      <td>0.798319</td>\n",
       "      <td>0.966375</td>\n",
       "      <td>0.931961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.907656</td>\n",
       "      <td>0.503819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shell weight</th>\n",
       "      <td>0.897706</td>\n",
       "      <td>0.905330</td>\n",
       "      <td>0.817338</td>\n",
       "      <td>0.955355</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>0.907656</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.627574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rings</th>\n",
       "      <td>0.556720</td>\n",
       "      <td>0.574660</td>\n",
       "      <td>0.557467</td>\n",
       "      <td>0.540390</td>\n",
       "      <td>0.420884</td>\n",
       "      <td>0.503819</td>\n",
       "      <td>0.627574</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Length  Diameter    Height  Whole weight  Shucked weight  \\\n",
       "Length          1.000000  0.986812  0.827554      0.925261        0.897914   \n",
       "Diameter        0.986812  1.000000  0.833684      0.925452        0.893162   \n",
       "Height          0.827554  0.833684  1.000000      0.819221        0.774972   \n",
       "Whole weight    0.925261  0.925452  0.819221      1.000000        0.969405   \n",
       "Shucked weight  0.897914  0.893162  0.774972      0.969405        1.000000   \n",
       "Viscera weight  0.903018  0.899724  0.798319      0.966375        0.931961   \n",
       "Shell weight    0.897706  0.905330  0.817338      0.955355        0.882617   \n",
       "Rings           0.556720  0.574660  0.557467      0.540390        0.420884   \n",
       "\n",
       "                Viscera weight  Shell weight     Rings  \n",
       "Length                0.903018      0.897706  0.556720  \n",
       "Diameter              0.899724      0.905330  0.574660  \n",
       "Height                0.798319      0.817338  0.557467  \n",
       "Whole weight          0.966375      0.955355  0.540390  \n",
       "Shucked weight        0.931961      0.882617  0.420884  \n",
       "Viscera weight        1.000000      0.907656  0.503819  \n",
       "Shell weight          0.907656      1.000000  0.627574  \n",
       "Rings                 0.503819      0.627574  1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets correlation matrix\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.523992</td>\n",
       "      <td>0.407881</td>\n",
       "      <td>0.139516</td>\n",
       "      <td>0.828742</td>\n",
       "      <td>0.359367</td>\n",
       "      <td>0.180594</td>\n",
       "      <td>0.238831</td>\n",
       "      <td>9.933684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.120093</td>\n",
       "      <td>0.099240</td>\n",
       "      <td>0.041827</td>\n",
       "      <td>0.490389</td>\n",
       "      <td>0.221963</td>\n",
       "      <td>0.109614</td>\n",
       "      <td>0.139203</td>\n",
       "      <td>3.224169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.441500</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.799500</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>1.153000</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.329000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>2.825500</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Length     Diameter       Height  Whole weight  Shucked weight  \\\n",
       "count  4177.000000  4177.000000  4177.000000   4177.000000     4177.000000   \n",
       "mean      0.523992     0.407881     0.139516      0.828742        0.359367   \n",
       "std       0.120093     0.099240     0.041827      0.490389        0.221963   \n",
       "min       0.075000     0.055000     0.000000      0.002000        0.001000   \n",
       "25%       0.450000     0.350000     0.115000      0.441500        0.186000   \n",
       "50%       0.545000     0.425000     0.140000      0.799500        0.336000   \n",
       "75%       0.615000     0.480000     0.165000      1.153000        0.502000   \n",
       "max       0.815000     0.650000     1.130000      2.825500        1.488000   \n",
       "\n",
       "       Viscera weight  Shell weight        Rings  \n",
       "count     4177.000000   4177.000000  4177.000000  \n",
       "mean         0.180594      0.238831     9.933684  \n",
       "std          0.109614      0.139203     3.224169  \n",
       "min          0.000500      0.001500     1.000000  \n",
       "25%          0.093500      0.130000     8.000000  \n",
       "50%          0.171000      0.234000     9.000000  \n",
       "75%          0.253000      0.329000    11.000000  \n",
       "max          0.760000      1.005000    29.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets draw a bar graph for Rings and Sex\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.barplot(x=\"Sex\",y=\"Rings\",data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0      0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1      0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2      0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3      0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4      0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "...      ...       ...     ...           ...             ...             ...   \n",
       "4172   0.565     0.450   0.165        0.8870          0.3700          0.2390   \n",
       "4173   0.590     0.440   0.135        0.9660          0.4390          0.2145   \n",
       "4174   0.600     0.475   0.205        1.1760          0.5255          0.2875   \n",
       "4175   0.625     0.485   0.150        1.0945          0.5310          0.2610   \n",
       "4176   0.710     0.555   0.195        1.9485          0.9455          0.3765   \n",
       "\n",
       "      Shell weight  Rings  Sex_I  Sex_M  \n",
       "0           0.1500     15      0      1  \n",
       "1           0.0700      7      0      1  \n",
       "2           0.2100      9      0      0  \n",
       "3           0.1550     10      0      1  \n",
       "4           0.0550      7      1      0  \n",
       "...            ...    ...    ...    ...  \n",
       "4172        0.2490     11      0      0  \n",
       "4173        0.2605     10      0      1  \n",
       "4174        0.3080      9      0      1  \n",
       "4175        0.2960     10      0      0  \n",
       "4176        0.4950     12      0      1  \n",
       "\n",
       "[4177 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final=pd.get_dummies(df,drop_first=True)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Length           -0.639873\n",
       "Diameter         -0.609198\n",
       "Height            3.128817\n",
       "Whole weight      0.530959\n",
       "Shucked weight    0.719098\n",
       "Viscera weight    0.591852\n",
       "Shell weight      0.620927\n",
       "Rings             1.114102\n",
       "Sex_I             0.765708\n",
       "Sex_M             0.557390\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check the skewness\n",
    "df_final.skew()\n",
    "# there are some values exeeding value of max 0.55 that mean skewness is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before treating skewnees lets divide the dataset into input and output\n",
    "df_x=df_final.drop(columns=[\"Rings\"])\n",
    "y=df_final[[\"Rings\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets remove the skewness\n",
    "for index in df_x.skew().index:\n",
    "    if df_x.skew().loc[index]>0.55:\n",
    "        df_x[index]=np.log1p(df_x[index])\n",
    "    if df_x.skew().loc[index]<-0.55:\n",
    "        df_x[index]=np.square(df_x[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Length           -0.068660\n",
       "Diameter         -0.026554\n",
       "Height            1.099602\n",
       "Whole weight      0.530959\n",
       "Shucked weight    0.306439\n",
       "Viscera weight    0.375637\n",
       "Shell weight      0.315321\n",
       "Sex_I             0.765708\n",
       "Sex_M             0.557390\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets again check the skewness\n",
    "df_x.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets use decision tree regressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "def maxr2_score(regr,df_x,y):\n",
    "    max_r_score=0\n",
    "    for r_state in range(42,100):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(df_x, y,random_state = r_state,test_size=0.20)\n",
    "        regr.fit(x_train,y_train)\n",
    "        y_pred = regr.predict(x_test)\n",
    "        r2_scr=r2_score(y_test,y_pred)\n",
    "        print(\"r2 score corresponding to \",r_state,\" is \",r2_scr)\n",
    "        if r2_scr>max_r_score:\n",
    "            max_r_score=r2_scr\n",
    "            final_r_state=r_state\n",
    "    print(\"max r2 score corresponding to \",final_r_state,\" is \",max_r_score)\n",
    "    return final_r_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score corresponding to  42  is  0.3751670693573995\n",
      "r2 score corresponding to  43  is  0.2733987506930774\n",
      "r2 score corresponding to  44  is  0.32668661036516333\n",
      "r2 score corresponding to  45  is  0.183634480564967\n",
      "r2 score corresponding to  46  is  0.2785949618626291\n",
      "r2 score corresponding to  47  is  0.14407598842073832\n",
      "r2 score corresponding to  48  is  0.3386596782526843\n",
      "r2 score corresponding to  49  is  0.30625767402768345\n",
      "r2 score corresponding to  50  is  0.2542920934996774\n",
      "r2 score corresponding to  51  is  0.3829978540903203\n",
      "r2 score corresponding to  52  is  0.281139806922883\n",
      "r2 score corresponding to  53  is  0.3695730611540423\n",
      "r2 score corresponding to  54  is  0.3028786384133748\n",
      "r2 score corresponding to  55  is  0.2030700073689028\n",
      "r2 score corresponding to  56  is  0.2647926879282202\n",
      "r2 score corresponding to  57  is  0.26784634754037684\n",
      "r2 score corresponding to  58  is  0.2930403524177596\n",
      "r2 score corresponding to  59  is  0.21670084851676108\n",
      "r2 score corresponding to  60  is  0.2695375989711507\n",
      "r2 score corresponding to  61  is  0.30436723886381245\n",
      "r2 score corresponding to  62  is  0.2902253906083613\n",
      "r2 score corresponding to  63  is  0.3856256928748433\n",
      "r2 score corresponding to  64  is  0.2884286880542616\n",
      "r2 score corresponding to  65  is  0.27213617737075513\n",
      "r2 score corresponding to  66  is  0.2883019027508835\n",
      "r2 score corresponding to  67  is  0.332544602371073\n",
      "r2 score corresponding to  68  is  0.2522163652153864\n",
      "r2 score corresponding to  69  is  0.25045039219240695\n",
      "r2 score corresponding to  70  is  0.3196738250602368\n",
      "r2 score corresponding to  71  is  0.2802307843822015\n",
      "r2 score corresponding to  72  is  0.33394929186638167\n",
      "r2 score corresponding to  73  is  0.2030551218040929\n",
      "r2 score corresponding to  74  is  0.28431674471087187\n",
      "r2 score corresponding to  75  is  0.2681006046598946\n",
      "r2 score corresponding to  76  is  0.31606193728286625\n",
      "r2 score corresponding to  77  is  0.2785874279375399\n",
      "r2 score corresponding to  78  is  0.3130325491934226\n",
      "r2 score corresponding to  79  is  0.27926154418370275\n",
      "r2 score corresponding to  80  is  0.3049809842977257\n",
      "r2 score corresponding to  81  is  0.35540856606637905\n",
      "r2 score corresponding to  82  is  0.2745254633893649\n",
      "r2 score corresponding to  83  is  0.2805439562815256\n",
      "r2 score corresponding to  84  is  0.2721083206304843\n",
      "r2 score corresponding to  85  is  0.4104114474797481\n",
      "r2 score corresponding to  86  is  0.28280369241964565\n",
      "r2 score corresponding to  87  is  0.26539828317594183\n",
      "r2 score corresponding to  88  is  0.2535145253036316\n",
      "r2 score corresponding to  89  is  0.3060485655633829\n",
      "r2 score corresponding to  90  is  0.29454216696344104\n",
      "r2 score corresponding to  91  is  0.27126301204257885\n",
      "r2 score corresponding to  92  is  0.25006138195670746\n",
      "r2 score corresponding to  93  is  0.29564615096103575\n",
      "r2 score corresponding to  94  is  0.2698652487458143\n",
      "r2 score corresponding to  95  is  0.274910107805417\n",
      "r2 score corresponding to  96  is  0.19636698830225496\n",
      "r2 score corresponding to  97  is  0.2841623653426911\n",
      "r2 score corresponding to  98  is  0.2695083148943106\n",
      "r2 score corresponding to  99  is  0.3236784551645563\n",
      "max r2 score corresponding to  85  is  0.4104114474797481\n"
     ]
    }
   ],
   "source": [
    "#Lets use decision tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "dtr=DecisionTreeRegressor()\n",
    "r_state=maxr2_score(dtr,df_x,np.log1p(y))\n",
    "#We can see this model is not performing well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets use random forest regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "rfr=RandomForestRegressor()\n",
    "parameters = {\"n_estimators\":[10,100,500,1000]}\n",
    "clf = GridSearchCV(rfr, parameters, cv=5)\n",
    "clf.fit(df_x, np.log1p(y))\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score corresponding to  42  is  0.6404896595800156\n",
      "r2 score corresponding to  43  is  0.6506895038768081\n",
      "r2 score corresponding to  44  is  0.6414076459086637\n",
      "r2 score corresponding to  45  is  0.5994225372795281\n",
      "r2 score corresponding to  46  is  0.6394371782791453\n",
      "r2 score corresponding to  47  is  0.5901884544266716\n",
      "r2 score corresponding to  48  is  0.6479516285421448\n",
      "r2 score corresponding to  49  is  0.61453150479795\n",
      "r2 score corresponding to  50  is  0.6314655522054238\n",
      "r2 score corresponding to  51  is  0.6677545306195676\n",
      "r2 score corresponding to  52  is  0.6576572869348452\n",
      "r2 score corresponding to  53  is  0.6542981087827595\n",
      "r2 score corresponding to  54  is  0.6002803477918355\n",
      "r2 score corresponding to  55  is  0.6210210947105461\n",
      "r2 score corresponding to  56  is  0.6293801886639309\n",
      "r2 score corresponding to  57  is  0.6401695662559124\n",
      "r2 score corresponding to  58  is  0.6462488937839492\n",
      "r2 score corresponding to  59  is  0.63658755796784\n",
      "r2 score corresponding to  60  is  0.6229040113767178\n",
      "r2 score corresponding to  61  is  0.633018270281513\n",
      "r2 score corresponding to  62  is  0.6336930008171484\n",
      "r2 score corresponding to  63  is  0.6548257170043255\n",
      "r2 score corresponding to  64  is  0.6295585786097508\n",
      "r2 score corresponding to  65  is  0.6294536903917407\n",
      "r2 score corresponding to  66  is  0.6443219710854589\n",
      "r2 score corresponding to  67  is  0.6405937996947848\n",
      "r2 score corresponding to  68  is  0.6075500439684007\n",
      "r2 score corresponding to  69  is  0.6402205931122839\n",
      "r2 score corresponding to  70  is  0.6334781601193777\n",
      "r2 score corresponding to  71  is  0.6229166099690786\n",
      "r2 score corresponding to  72  is  0.6305166757108065\n",
      "r2 score corresponding to  73  is  0.6098368238904757\n",
      "r2 score corresponding to  74  is  0.6102434547773334\n",
      "r2 score corresponding to  75  is  0.6196453750799589\n",
      "r2 score corresponding to  76  is  0.6137416767276731\n",
      "r2 score corresponding to  77  is  0.6459458570761049\n",
      "r2 score corresponding to  78  is  0.6282392130828514\n",
      "r2 score corresponding to  79  is  0.6311724194715894\n",
      "r2 score corresponding to  80  is  0.6378978779389903\n",
      "r2 score corresponding to  81  is  0.6531392353054626\n",
      "r2 score corresponding to  82  is  0.6613552279141968\n",
      "r2 score corresponding to  83  is  0.6027766749817696\n",
      "r2 score corresponding to  84  is  0.5997401874780257\n",
      "r2 score corresponding to  85  is  0.6471173774895678\n",
      "r2 score corresponding to  86  is  0.6116763570764239\n",
      "r2 score corresponding to  87  is  0.6092698972873948\n",
      "r2 score corresponding to  88  is  0.6657970542595532\n",
      "r2 score corresponding to  89  is  0.6642559515441793\n",
      "r2 score corresponding to  90  is  0.6106597119582577\n",
      "r2 score corresponding to  91  is  0.6349266520676823\n",
      "r2 score corresponding to  92  is  0.5994122166648608\n",
      "r2 score corresponding to  93  is  0.6473817609973835\n",
      "r2 score corresponding to  94  is  0.6443321186127262\n",
      "r2 score corresponding to  95  is  0.6522630315377183\n",
      "r2 score corresponding to  96  is  0.6250488093412012\n",
      "r2 score corresponding to  97  is  0.6417428486731026\n",
      "r2 score corresponding to  98  is  0.6112354437210881\n",
      "r2 score corresponding to  99  is  0.6383297870420386\n",
      "max r2 score corresponding to  51  is  0.6677545306195676\n"
     ]
    }
   ],
   "source": [
    "#Lets use maxr2_score function\n",
    "rfr=RandomForestRegressor(n_estimators=1000)\n",
    "r_state=maxr2_score(rfr,df_x,np.log1p(y))\n",
    "#Below scores are better than what we saw with decision tree but random fores is some what slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.547876614572844"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check the mean r2_score with random forest\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(rfr,df_x,np.log1p(y),cv=10,scoring=\"r2\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 14}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets use KNN regressor but we will find the otimal value of n_neigbors using grid search\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knr=KNeighborsRegressor()\n",
    "parameters = {\"n_neighbors\":range(2,30)}\n",
    "clf = GridSearchCV(knr, parameters, cv=10)\n",
    "clf.fit(df_x, np.log1p(y))\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score corresponding to  42  is  0.6380252775314894\n",
      "r2 score corresponding to  43  is  0.6291736948440889\n",
      "r2 score corresponding to  44  is  0.6303229575330269\n",
      "r2 score corresponding to  45  is  0.597230407556341\n",
      "r2 score corresponding to  46  is  0.6242733368201714\n",
      "r2 score corresponding to  47  is  0.5748674244981291\n",
      "r2 score corresponding to  48  is  0.6403110778886996\n",
      "r2 score corresponding to  49  is  0.6199019909994048\n",
      "r2 score corresponding to  50  is  0.6035158455015835\n",
      "r2 score corresponding to  51  is  0.6295522289271691\n",
      "r2 score corresponding to  52  is  0.6203751413251674\n",
      "r2 score corresponding to  53  is  0.6328301054806752\n",
      "r2 score corresponding to  54  is  0.5842777182067207\n",
      "r2 score corresponding to  55  is  0.6110368836145803\n",
      "r2 score corresponding to  56  is  0.6239313108839961\n",
      "r2 score corresponding to  57  is  0.613478510565195\n",
      "r2 score corresponding to  58  is  0.6423948578943581\n",
      "r2 score corresponding to  59  is  0.6289106507552829\n",
      "r2 score corresponding to  60  is  0.6172381535275533\n",
      "r2 score corresponding to  61  is  0.6058885416155875\n",
      "r2 score corresponding to  62  is  0.6247457199675708\n",
      "r2 score corresponding to  63  is  0.6304164144282866\n",
      "r2 score corresponding to  64  is  0.6017167518383171\n",
      "r2 score corresponding to  65  is  0.6076265950418447\n",
      "r2 score corresponding to  66  is  0.6076796014919494\n",
      "r2 score corresponding to  67  is  0.6176763856485206\n",
      "r2 score corresponding to  68  is  0.5841821930287651\n",
      "r2 score corresponding to  69  is  0.6081601042406\n",
      "r2 score corresponding to  70  is  0.5992407055513265\n",
      "r2 score corresponding to  71  is  0.6096686614205327\n",
      "r2 score corresponding to  72  is  0.5954734980476841\n",
      "r2 score corresponding to  73  is  0.5983368269467622\n",
      "r2 score corresponding to  74  is  0.5954067805869837\n",
      "r2 score corresponding to  75  is  0.5978624674503343\n",
      "r2 score corresponding to  76  is  0.6412098230967818\n",
      "r2 score corresponding to  77  is  0.619611297728641\n",
      "r2 score corresponding to  78  is  0.6202817816472521\n",
      "r2 score corresponding to  79  is  0.6048611191524464\n",
      "r2 score corresponding to  80  is  0.6067799456911145\n",
      "r2 score corresponding to  81  is  0.6382302688167845\n",
      "r2 score corresponding to  82  is  0.6466137473260631\n",
      "r2 score corresponding to  83  is  0.6043536115192569\n",
      "r2 score corresponding to  84  is  0.5838553687852942\n",
      "r2 score corresponding to  85  is  0.6206731026328102\n",
      "r2 score corresponding to  86  is  0.5953964198341342\n",
      "r2 score corresponding to  87  is  0.6108134135779949\n",
      "r2 score corresponding to  88  is  0.653737820817224\n",
      "r2 score corresponding to  89  is  0.6476802276062554\n",
      "r2 score corresponding to  90  is  0.5795369313748742\n",
      "r2 score corresponding to  91  is  0.6193193458074975\n",
      "r2 score corresponding to  92  is  0.5867218759804684\n",
      "r2 score corresponding to  93  is  0.6322470182579972\n",
      "r2 score corresponding to  94  is  0.6239083267577747\n",
      "r2 score corresponding to  95  is  0.6258564840461018\n",
      "r2 score corresponding to  96  is  0.593471407707169\n",
      "r2 score corresponding to  97  is  0.6103636502357949\n",
      "r2 score corresponding to  98  is  0.598484510748902\n",
      "r2 score corresponding to  99  is  0.6291055747228709\n",
      "max r2 score corresponding to  88  is  0.653737820817224\n"
     ]
    }
   ],
   "source": [
    "#Lets use n_neighbors as found above and use maxr2_score function\n",
    "knr=KNeighborsRegressor(n_neighbors=14)\n",
    "r_state=maxr2_score(knr,df_x,np.log1p(y))\n",
    "#KNN is giving same r2 score as rando forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5519598111881933"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets find meean r2 score using cross_val score function\n",
    "cross_val_score(knr,df_x,np.log1p(y),cv=10,scoring=\"r2\").mean()\n",
    "#Here mean r2 score is better than random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets use KNN regressor and save it as our final model\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x, y,random_state = r_state,test_size=0.25)\n",
    "y_train=np.log1p(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr=RandomForestRegressor(n_estimators=1000)\n",
    "rfr.fit(x_train,y_train)\n",
    "y_pred=rfr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is:  2.115791884142322\n",
      "r2_score is:  0.5690987017330101\n"
     ]
    }
   ],
   "source": [
    "#Lets find the rmse and r2_score using sklearn.metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"RMSE is: \",np.sqrt(mean_squared_error(y_test,np.expm1(y_pred))))\n",
    "print(\"r2_score is: \",r2_score(y_test,np.expm1(y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
